{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3c25bb-fdd7-4dd6-a0e9-1139101bc243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ba04af-65bd-4520-9252-d592c864da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_copy_video_list(\n",
    "    annotation_path, \n",
    "    source_image_dir, \n",
    "    output_dir, \n",
    "    target_video_ids\n",
    "):\n",
    "    \"\"\"\n",
    "    Filters COCO annotations for a LIST of video_ids and copies relevant images.\n",
    "    \"\"\"\n",
    "    # 1. Setup Directories\n",
    "    output_img_dir = os.path.join(output_dir, 'images')\n",
    "    os.makedirs(output_img_dir, exist_ok=True)\n",
    "    \n",
    "    # 2. Load the original annotation file\n",
    "    print(f\"Loading annotations from: {annotation_path}\")\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "        \n",
    "    # OPTIMIZATION: Convert target list to a set for faster lookup\n",
    "    target_set = set(target_video_ids)\n",
    "    \n",
    "    # 3. Filter Images\n",
    "    # Check if the image's video_id is inside our target set\n",
    "    filtered_images = [\n",
    "        img for img in coco_data['images'] \n",
    "        if img.get('video_id') in target_set\n",
    "    ]\n",
    "    \n",
    "    if not filtered_images:\n",
    "        print(f\"No images found for the provided Video IDs: {target_video_ids}\")\n",
    "        return\n",
    "\n",
    "    # Create a set of valid image IDs for O(1) annotation lookup\n",
    "    valid_img_ids = set(img['id'] for img in filtered_images)\n",
    "    \n",
    "    # 4. Filter Annotations\n",
    "    filtered_annotations = [\n",
    "        ann for ann in coco_data['annotations'] \n",
    "        if ann['image_id'] in valid_img_ids\n",
    "    ]\n",
    "    \n",
    "    # 5. Filter Videos Metadata\n",
    "    filtered_videos = [\n",
    "        vid for vid in coco_data.get('videos', []) \n",
    "        if vid['id'] in target_set\n",
    "    ]\n",
    "\n",
    "    # 6. Construct New JSON Object\n",
    "    new_coco_data = {\n",
    "        'info': coco_data.get('info', {}),\n",
    "        'licenses': coco_data.get('licenses', []),\n",
    "        'categories': coco_data.get('categories', []),\n",
    "        'videos': filtered_videos,\n",
    "        'images': filtered_images,\n",
    "        'annotations': filtered_annotations\n",
    "    }\n",
    "    \n",
    "    # 7. Copy Images\n",
    "    print(f\"Found {len(filtered_images)} images across {len(target_set)} videos.\")\n",
    "    print(f\"Copying to {output_img_dir}...\")\n",
    "    \n",
    "    count = 0\n",
    "    for img in filtered_images:\n",
    "        src_path = os.path.join(source_image_dir, img['file_name'])\n",
    "        dst_path = os.path.join(output_img_dir, os.path.basename(img['file_name']))\n",
    "        \n",
    "        # Check if source exists\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            count += 1\n",
    "            # Optional: Print progress every 100 images\n",
    "            if count % 100 == 0:\n",
    "                print(f\"Copied {count} images...\", end='\\r')\n",
    "        else:\n",
    "            print(f\"Warning: Source image not found: {src_path}\")\n",
    "\n",
    "    print(f\"\\nFinished copying {count} images.\")\n",
    "\n",
    "    # 8. Save Filtered JSON\n",
    "    output_json_path = os.path.join(output_dir, 'filtered_annotations.json')\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(new_coco_data, f, indent=4)\n",
    "        \n",
    "    print(f\"Done! New annotation file saved at: {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460877c-447a-43e5-9d85-e7eaa73a0b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44c96d3-384f-4520-8e7e-54f9afb4e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224be22d-1666-40e5-ac00-dc986063558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load dataset ===\n",
    "json_path_train =  r'I:\\Dataset\\annotations\\instances_train_objects_in_water.json'\n",
    "json_path_val =  r'I:\\Dataset\\annotations\\instances_val_objects_in_water.json'\n",
    "json_path_test =  r'I:\\Dataset\\annotations\\instances_test_objects_in_water.json'\n",
    "with open(json_path_train, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(json_path_val, 'r') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "with open(json_path_test, 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5b55800-8ed5-45ff-b2ac-dd61f14bb6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_image_ext(data):\n",
    "    for img in data[\"images\"]:\n",
    "        if img[\"file_name\"].endswith(\".png\"):\n",
    "            img[\"file_name\"] = img[\"file_name\"].replace(\".png\", \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4403f1b1-4100-4850-91ea-0f63104ffc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_image_ext(train_data)\n",
    "fix_image_ext(val_data)\n",
    "fix_image_ext(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "168561f8-0222-4060-b74f-0b08501cab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing category ID 6 ('life jacket')\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Find the category_id for \"life jacket\"\n",
    "life_jacket_ids = [c['id'] for c in train_data['categories'] if c['name'] == 'life jacket']\n",
    "\n",
    "if life_jacket_ids:\n",
    "    life_jacket_id = life_jacket_ids[0]\n",
    "    print(f\"Removing category ID {life_jacket_id} ('life jacket')\")\n",
    "\n",
    "    # Step 2: Remove the category entry\n",
    "    train_data['categories'] = [c for c in train_data['categories'] if c['id'] != life_jacket_id]\n",
    "\n",
    "    # Step 3: Remove all annotations for that category\n",
    "    train_data['annotations'] = [a for a in train_data['annotations'] if a['category_id'] != life_jacket_id]\n",
    "\n",
    "else:\n",
    "    print(\"'life jacket' class not found in categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca696cba-2f4d-4f86-adc6-966ff687d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in train_data[\"annotations\"]:\n",
    "    if \"iscrowd\" not in ann:\n",
    "        ann[\"iscrowd\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740b27fe-e399-411e-80c6-20facb4db16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in val_data[\"annotations\"]:\n",
    "    if \"iscrowd\" not in ann:\n",
    "        ann[\"iscrowd\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "685bc409-5c54-4548-b49d-e7c5d1914ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remapping: {1: 0, 2: 1, 3: 2}\n"
     ]
    }
   ],
   "source": [
    "# Collect all category ids\n",
    "cats = sorted({cat[\"id\"] for cat in train_data[\"categories\"]})\n",
    "id_map = {old: new for new, old in enumerate(cats)}  # remap to 0..N-1\n",
    "\n",
    "print(\"Remapping:\", id_map)\n",
    "\n",
    "# Fix annotations\n",
    "for ann in train_data[\"annotations\"]:\n",
    "    ann[\"category_id\"] = id_map[ann[\"category_id\"]]\n",
    "\n",
    "# Fix categories list\n",
    "for cat in train_data[\"categories\"]:\n",
    "    cat[\"id\"] = id_map[cat[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fdeffcc-2b22-42b6-ad57-5018d69eb452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Remapping: {1: 0, 2: 1, 3: 2}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Keep only categories you want (1,2,3) and drop 6\n",
    "valid_ids = {1, 2, 3}\n",
    "val_data[\"categories\"] = [cat for cat in val_data[\"categories\"] if cat[\"id\"] in valid_ids]\n",
    "val_data[\"annotations\"] = [ann for ann in val_data[\"annotations\"] if ann[\"category_id\"] in valid_ids]\n",
    "\n",
    "# Step 2: Remap remaining categories to 0..N-1\n",
    "cats = sorted({cat[\"id\"] for cat in val_data[\"categories\"]})\n",
    "id_map = {old: new for new, old in enumerate(cats)}\n",
    "print(\"Final Remapping:\", id_map)\n",
    "\n",
    "# Apply remap\n",
    "for ann in val_data[\"annotations\"]:\n",
    "    ann[\"category_id\"] = id_map[ann[\"category_id\"]]\n",
    "\n",
    "for cat in val_data[\"categories\"]:\n",
    "    cat[\"id\"] = id_map[cat[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d981b697-dec1-49a1-a3c8-07d5a9d15b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'F:\\Dataset\\annotations\\train.json', \"w\") as f:\n",
    "    json.dump(train_data, f, indent=4)\n",
    "\n",
    "with open(r'F:\\Dataset\\annotations\\test.json', \"w\") as f:\n",
    "    json.dump(test_data, f, indent=4)\n",
    "\n",
    "with open(r'F:\\Dataset\\annotations\\val.json', \"w\") as f:\n",
    "    json.dump(val_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf29e0b4-7373-4bd4-906a-89db3a0492f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations from: F:\\Dataset\\annotations\\train.json\n",
      "Found 20256 images across 12 videos.\n",
      "Copying to F:\\Dataset\\images...\n",
      "Copied 20200 images...\n",
      "Finished copying 20256 images.\n",
      "Done! New annotation file saved at: F:\\Dataset\\filtered_annotations.json\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "ANNOTATION_FILE = r'F:\\Dataset\\annotations\\train.json'\n",
    "SOURCE_IMAGES = r'I:\\Dataset\\Compressed\\train'\n",
    "OUTPUT_DIRECTORY = r'F:\\Dataset'\n",
    "\n",
    "# *** DEFINE YOUR LIST OF IDS HERE ***\n",
    "VIDEO_IDS_TO_EXTRACT = [0, 5, 7, 8, 9, 12, 13, 14, 15, 18, 19, 21] \n",
    "\n",
    "# Run the function\n",
    "filter_and_copy_video_list(\n",
    "    ANNOTATION_FILE, \n",
    "    SOURCE_IMAGES, \n",
    "    OUTPUT_DIRECTORY, \n",
    "    VIDEO_IDS_TO_EXTRACT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c90b1c99-3094-4b10-9177-4b7655141160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations from: F:\\Dataset\\annotations\\val.json\n",
      "Found 4782 images across 11 videos.\n",
      "Copying to F:\\Dataset\\images...\n",
      "Copied 4700 images...\n",
      "Finished copying 4782 images.\n",
      "Done! New annotation file saved at: F:\\Dataset\\filtered_annotations.json\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "ANNOTATION_FILE = r'F:\\Dataset\\annotations\\val.json'\n",
    "SOURCE_IMAGES = r'I:\\Dataset\\Compressed\\val'\n",
    "OUTPUT_DIRECTORY = r'F:\\Dataset'\n",
    "\n",
    "# *** DEFINE YOUR LIST OF IDS HERE ***\n",
    "VIDEO_IDS_TO_EXTRACT = [0, 5, 9, 11, 12, 13, 15, 17, 18, 19, 21] \n",
    "\n",
    "# Run the function\n",
    "filter_and_copy_video_list(\n",
    "    ANNOTATION_FILE, \n",
    "    SOURCE_IMAGES, \n",
    "    OUTPUT_DIRECTORY, \n",
    "    VIDEO_IDS_TO_EXTRACT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5069d52-c594-43d9-90d0-cf3a4c19a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JSON from F:\\Dataset\\annotations\\train.json...\n",
      "Mapping Categories:\n",
      "  - COCO ID 0 (swimmer) -> YOLO ID 0\n",
      "  - COCO ID 1 (swimmer with life jacket) -> YOLO ID 1\n",
      "  - COCO ID 2 (boat) -> YOLO ID 2\n",
      "\n",
      "Processing 20256 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20256/20256 [01:53<00:00, 177.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success! Dataset prepared at: F:\\Dataset\\yolo_dataset\n",
      "YAML file created at: F:\\Dataset\\yolo_dataset\\data.yaml\n",
      "Use this command to train: yolo detect train data=F:\\Dataset\\yolo_dataset\\data.yaml model=yolov8n.pt epochs=100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm  # pip install tqdm\n",
    "\n",
    "def convert_coco_to_yolo_v8(json_path, source_image_dir, output_dir, subset_name='train'):\n",
    "    \"\"\"\n",
    "    Converts COCO JSON annotations to YOLOv8 format (normalized xywh).\n",
    "    \n",
    "    Args:\n",
    "        json_path (str): Path to the filtered .json file.\n",
    "        source_image_dir (str): Folder containing the source images.\n",
    "        output_dir (str): Where to save the YOLO dataset (e.g., './yolo_dataset').\n",
    "        subset_name (str): 'train', 'val', or 'test'. Used for folder naming.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Setup Directories\n",
    "    # YOLOv8 standard structure: output_dir/train/images and output_dir/train/labels\n",
    "    images_output_dir = os.path.join(output_dir, subset_name, 'images')\n",
    "    labels_output_dir = os.path.join(output_dir, subset_name, 'labels')\n",
    "    \n",
    "    os.makedirs(images_output_dir, exist_ok=True)\n",
    "    os.makedirs(labels_output_dir, exist_ok=True)\n",
    "    \n",
    "    # 2. Load JSON\n",
    "    print(f\"Loading JSON from {json_path}...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # 3. Create Category Mapping\n",
    "    # YOLO requires class indices to be 0, 1, 2... \n",
    "    # COCO IDs might be non-contiguous (e.g., 1, 3, 10). We map them here.\n",
    "    categories = data['categories']\n",
    "    # Sort by ID to ensure consistent ordering\n",
    "    categories.sort(key=lambda x: x['id'])\n",
    "    \n",
    "    coco_id_to_yolo_index = {}\n",
    "    yolo_class_names = []\n",
    "    \n",
    "    print(\"Mapping Categories:\")\n",
    "    for index, cat in enumerate(categories):\n",
    "        coco_id = cat['id']\n",
    "        name = cat['name']\n",
    "        coco_id_to_yolo_index[coco_id] = index\n",
    "        yolo_class_names.append(name)\n",
    "        print(f\"  - COCO ID {coco_id} ({name}) -> YOLO ID {index}\")\n",
    "\n",
    "    # 4. Group Annotations by Image ID\n",
    "    img_id_to_anns = {}\n",
    "    for ann in data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in img_id_to_anns:\n",
    "            img_id_to_anns[img_id] = []\n",
    "        img_id_to_anns[img_id].append(ann)\n",
    "        \n",
    "    # 5. Process Images and Generate Labels\n",
    "    print(f\"\\nProcessing {len(data['images'])} images...\")\n",
    "    \n",
    "    for img_info in tqdm(data['images']):\n",
    "        img_id = img_info['id']\n",
    "        file_name = img_info['file_name']\n",
    "        \n",
    "        # COCO Bbox: [x_min, y_min, width, height]\n",
    "        # YOLO Bbox: [x_center, y_center, width, height] (Normalized 0-1)\n",
    "        \n",
    "        img_w = img_info['width']\n",
    "        img_h = img_info['height']\n",
    "        \n",
    "        # Handle Annotation File (.txt)\n",
    "        # Change extension from .jpg/.png to .txt\n",
    "        txt_filename = os.path.splitext(os.path.basename(file_name))[0] + \".txt\"\n",
    "        txt_path = os.path.join(labels_output_dir, txt_filename)\n",
    "        \n",
    "        with open(txt_path, 'w') as f_txt:\n",
    "            if img_id in img_id_to_anns:\n",
    "                for ann in img_id_to_anns[img_id]:\n",
    "                    coco_bbox = ann['bbox']\n",
    "                    category_id = ann['category_id']\n",
    "                    \n",
    "                    # Convert to YOLO format\n",
    "                    x_min, y_min, w, h = coco_bbox\n",
    "                    \n",
    "                    # Calculate Center\n",
    "                    x_center = x_min + (w / 2)\n",
    "                    y_center = y_min + (h / 2)\n",
    "                    \n",
    "                    # Normalize\n",
    "                    x_c_norm = x_center / img_w\n",
    "                    y_c_norm = y_center / img_h\n",
    "                    w_norm = w / img_w\n",
    "                    h_norm = h / img_h\n",
    "                    \n",
    "                    # Clamp values to 0-1 to avoid errors\n",
    "                    x_c_norm = max(0, min(1, x_c_norm))\n",
    "                    y_c_norm = max(0, min(1, y_c_norm))\n",
    "                    w_norm = max(0, min(1, w_norm))\n",
    "                    h_norm = max(0, min(1, h_norm))\n",
    "                    \n",
    "                    class_idx = coco_id_to_yolo_index[category_id]\n",
    "                    \n",
    "                    # Write line: class_id x_c y_c w h\n",
    "                    f_txt.write(f\"{class_idx} {x_c_norm:.6f} {y_c_norm:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "        \n",
    "        # Handle Image File (Copying)\n",
    "        src_img_path = os.path.join(source_image_dir, os.path.basename(file_name))\n",
    "        dst_img_path = os.path.join(images_output_dir, os.path.basename(file_name))\n",
    "        \n",
    "        if os.path.exists(src_img_path):\n",
    "            shutil.copy2(src_img_path, dst_img_path)\n",
    "        else:\n",
    "            print(f\"Warning: Image not found {src_img_path}\")\n",
    "\n",
    "    # 6. Generate data.yaml\n",
    "    # We create the YAML file in the root of the output directory\n",
    "    yaml_content = {\n",
    "        'path': os.path.abspath(output_dir), # Absolute path to dataset root\n",
    "        'train': os.path.join(subset_name, 'images'),\n",
    "        'val': os.path.join(subset_name, 'images'), # Using same split for val as demo\n",
    "        'names': {i: name for i, name in enumerate(yolo_class_names)}\n",
    "    }\n",
    "    \n",
    "    yaml_path = os.path.join(output_dir, 'data.yaml')\n",
    "    with open(yaml_path, 'w') as f_yaml:\n",
    "        yaml.dump(yaml_content, f_yaml, sort_keys=False)\n",
    "        \n",
    "    print(f\"\\nSuccess! Dataset prepared at: {output_dir}\")\n",
    "    print(f\"YAML file created at: {yaml_path}\")\n",
    "    print(f\"Use this command to train: yolo detect train data={yaml_path} model=yolov8n.pt epochs=100\")\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# The folder created in the PREVIOUS step (containing 'filtered_annotations.json' and 'images' folder)\n",
    "# --- CONFIGURATION ---\n",
    "PREVIOUS_OUTPUT_FOLDER = r'F:\\Dataset'\n",
    "\n",
    "# FIXED: Removed the leading '\\' from the second arguments\n",
    "JSON_FILE = os.path.join(PREVIOUS_OUTPUT_FOLDER, 'annotations', 'train.json')\n",
    "SOURCE_IMAGES = os.path.join(PREVIOUS_OUTPUT_FOLDER, 'images', 'train')\n",
    "\n",
    "# Where you want the final YOLO dataset to be\n",
    "# Note: The script creates a 'train' folder inside this, so consider naming it 'yolo_dataset'\n",
    "FINAL_YOLO_DATASET_DIR = r'F:\\Dataset\\yolo_dataset' \n",
    "\n",
    "# Run Conversion\n",
    "convert_coco_to_yolo_v8(\n",
    "    JSON_FILE, \n",
    "    SOURCE_IMAGES, \n",
    "    FINAL_YOLO_DATASET_DIR, \n",
    "    subset_name='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f094ed0-c62e-4d2c-afb4-e88eabfe9bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JSON from F:\\Dataset\\annotations\\val.json...\n",
      "Mapping Categories:\n",
      "  - COCO ID 0 (swimmer) -> YOLO ID 0\n",
      "  - COCO ID 1 (swimmer with life jacket) -> YOLO ID 1\n",
      "  - COCO ID 2 (boat) -> YOLO ID 2\n",
      "\n",
      "Processing 4782 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4782/4782 [00:34<00:00, 140.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success! Dataset prepared at: F:\\Dataset\\yolo_dataset\n",
      "YAML file created at: F:\\Dataset\\yolo_dataset\\data.yaml\n",
      "Use this command to train: yolo detect train data=F:\\Dataset\\yolo_dataset\\data.yaml model=yolov8n.pt epochs=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PREVIOUS_OUTPUT_FOLDER = r'F:\\Dataset'\n",
    "\n",
    "# FIXED: Removed the leading '\\' from the second arguments\n",
    "JSON_FILE = os.path.join(PREVIOUS_OUTPUT_FOLDER, 'annotations', 'val.json')\n",
    "SOURCE_IMAGES = os.path.join(PREVIOUS_OUTPUT_FOLDER, 'images', 'val')\n",
    "\n",
    "# Where you want the final YOLO dataset to be\n",
    "# Note: The script creates a 'train' folder inside this, so consider naming it 'yolo_dataset'\n",
    "FINAL_YOLO_DATASET_DIR = r'F:\\Dataset\\yolo_dataset' \n",
    "\n",
    "# Run Conversion\n",
    "convert_coco_to_yolo_v8(\n",
    "    JSON_FILE, \n",
    "    SOURCE_IMAGES, \n",
    "    FINAL_YOLO_DATASET_DIR, \n",
    "    subset_name='val'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DroneVision2",
   "language": "python",
   "name": "dronevision2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
